from __future__ import annotations
from datetime import datetime, timedelta
import pendulum

from airflow import DAG, Dataset
from airflow.operators.bash import BashOperator

default_args = {
    'owner': 'haipn',
    'retries': 5,
    'retry_delay': timedelta(minutes=2)
}
# [START dataset_def]
dag1_dataset = Dataset('s3://dag1/output_1.txt', extra={'hi': 'bye'})
# [END dataset_def]
dag2_dataset = Dataset('s3://dag2/output_1.txt', extra={'hi': 'bye'})

with DAG(
    dag_id='Jar_File_Dag',
    default_args=default_args,
    description='This is our first dag that we write',
    start_date=datetime(2022, 10, 25),
    schedule_interval='0 */24 * * *'
) as dag1:
    # [START task_outlet]
    BashOperator(outlets=[dag1_dataset], task_id='run_Jar_File_Task',
        bash_command="java -jar /Users/haipn/Desktop/java_achive/helloWorld.jar"
    )